#' @title Predict method for dfunc objects
#' 
#' @description Predict likelihood parameters for distance function objects
#' 
#' @param object An estimated dfunc object.  See \code{dfuncEstim}. 
#' 
#' @param newdata A data frame containing new values of 
#' the covariates at which predictions are to be computed. If \code{newdata}
#' is NULL, predictions are made at values of all observations .  
#' 
#' @param type The type of predictions desired. If 
#' \code{type} = "parameters", return 
#' predicted canonical parameters of the likelihood function(s).  If 
#' type == "dfuncs", return the scaled distance function at distances   
#' specified in \code{distances} for all observations in \code{newdata}.
#' 
#' @param distances The vector of distances at which to predict scaled distance 
#' functions if \code{type == "dfuncs"}.  Distances outside the observation 
#' strip (\code{object$w.lo} to \code{object$w.hi}) are discarded.  If 
#' \code{distances} is NULL, this routine uses a sequen e of 200 evenly 
#' spaced distances from 
#' \code{object$w.lo} to \code{object$w.hi}. 
#'
#' @param \dots Included for compatibility with generic \code{predict} methods.
#' 
#' @return A matrix of predicted parameters of the likelihood used to estimate
#' the distance function
#' in \code{dfunc}. The extent of the first dimension (rows) in 
#' the returned matrix is equal to either the number of detection distances 
#' in \code{detectionData} or number of rows in \code{newdata}. 
#' The returned matrix's second dimension (columns) is 
#' the number of canonical parameters in the likelihood 
#' plus the number of expansion terms.  Without expansion terms, the number 
#' of columns in the returned matrix 
#' is either 1 or 2 depending on the likelihood (e.g., \code{halfnorm} has 
#' one parameter, \code{hazrate} has two). See the help 
#' for each likelihoods to interpret the returned parameter values.
#' 
#' @seealso \code{\link{halfnorm.like}}, \code{\link{negexp.like}}, 
#' \code{\link{uniform.like}}, \code{\link{hazrate.like}}, \code{\link{Gamma.like}}
#' 
#' @export
#' 
#' @importFrom stats terms as.formula delete.response model.frame model.matrix coef
#' 

# Extra Roxygen comments when we get around implmenting other types of
# predictions 
# Type = "inflation" predicts the inflation factor for all
# observations.  Inflation factors use likelihood parameters to compute
# effective sampling distances (ESW or EDR) and inverts them.
# type = "function" predicts the actual distance functions
predict.dfunc <- function(object
                        , newdata = NULL
                        , type = c("parameters")
                        , distances = NULL
                        , ...) {
  
  if (!inherits(object, "dfunc")){ 
    stop("object is not a 'dfunc' object")
  }
  
  hasCovars <- !is.null(object$covars)
  
  if (missing(newdata) || is.null(newdata)) {
    n <- length(object$dist)
  } else {
    n <- nrow(newdata)
  }
  
    
  # PARAMETER prediction ----
  # We always need parameters
  if(hasCovars){
    # X is the covariate matrix for predictions 
    if (missing(newdata) || is.null(newdata)) {
      # Case: Use original covars
      X <- object$covars
    } else {
      # Case: Pull formula to make covars from NEWDATA
      # (jdc, 6/25/2018) bug fix suggested by Diem
      # formula is stored, don't try and extract from call (which fails if formula is generated by paste)
      # Terms <- terms(as.formula(object$call[["formula"]]))
      # (tlm, 9/15/2022) model frame is stored in object. Safest formula to use 
      # is there
      # Terms <- terms(as.formula(object$formula))  # Jason's bug fix
      Terms <- terms( object$model.frame )
      Terms <- delete.response( Terms )
      xLevs <- lapply( object$model.frame, levels )
      m <- model.frame( Terms, newdata, xlev = xLevs )
      X <- model.matrix( Terms, m, contrasts.arg = attr(object$covars,"contrasts") )
    }
    
    BETA <- coef(object)
    beta <- BETA[1:ncol(X)]   # could be extra parameters tacked on. e.g., knee for logistc or expansion terms
    params <- X %*% beta
    params <- exp(params)  # All link functions are exp...thus far
    if(ncol(X)<length(BETA)){
      extraParams <- matrix(BETA[(ncol(X)+1):length(BETA)]
                          , nrow = n
                          , ncol = length(BETA)-ncol(X)
                          , byrow = TRUE)
      params <- cbind(params, extraParams)
    }
  } else {
    params <- coef(object) 
    params <- matrix(params, nrow=n, ncol=length(params), byrow=TRUE)
  }
    
  if( type == "parameters" ){
    return(params)
  }

  # DISTANCE function prediction ----
  
  # After next apply, y is length(x.seq) x nrow(parms).  
  # Each column is a unscaled distance function (f(x))
  
  like <- match.fun( paste( object$like.form, ".like", sep=""))
  zero <- units::as_units(0, object$outputUnits)
  
  if( is.null(distances) ){
    distances <- seq( object$w.lo, object$w.hi, length = 200)
  } else {
    # Make sure input distances are converted properly b.c. likelihoods drop units.
    distances <- units::set_units(distances, object$outputUnits, mode = "standard")
  }
  
  if( !hasCovars ){
    # cut the params down because everything is constant without covars
    params <- params[1, , drop = FALSE]
    X <- matrix(1, nrow = 1, ncol = 1) 
  }
  
  y <- apply(X = params
             , MARGIN = 1
             , FUN = like
             , dist = distances - object$w.lo
             , series = object$series
             , covars = NULL
             , expansions = object$expansions
             , w.lo = zero
             , w.hi = object$w.hi - object$w.lo
             , pointSurvey = FALSE
             , scale = TRUE
  )  
    
  y <- t(y)  # now, each row of y is a dfunc
    
  # At this point, we have unscaled distance functions in rows of y.
  
  # SCALE distance functions ----
    
  if( object$like.form == "Gamma" ){
    # This is a pesky special case of scaling. We need different x.scl for 
    # every distance function b.c. only x.scl = max is allowed.  For all other 
    # distance functions there is only one x.scl.
    # We could do all distance functions this way, i.e., call F.gx.estim
    # for every value of params, but it is faster not to. For all but Gamma,
    # we computed x.scl in dfuncEstim and it's constant.
    #
    # Cannot take apply(y,1,max) because maybe only 1 or 2 distances are predicted.
    # Cannot compute mode of Gamma (lam * b * (r-1)) because there might be extensions,
    # which change the mode.
    # Must call maximize.g which uses optim to find maximum.
    #
    maximize.g.reparam <- function( covRow, fit, hasCovars ){
      if( hasCovars ){
        # On entry from apply(), covRow is a dimensionless vector. It must be a
        # matrix when we call the likelihood.
        covRow <- matrix(covRow, nrow = 1)
      } else {
        covRow <- NULL
      }
      F.maximize.g(fit, covars = covRow)
    }
    
    x0 <- apply(X = X
                     , MARGIN = 1
                     , FUN = maximize.g.reparam
                     , fit = object
                     , hasCovars = hasCovars
                )
    # x0 is a distance, needs units
    x0 <- units::set_units(x0, object$outputUnits, mode = "standard")
    
  } else {
    # Case:  All likelihoods except Gamma
    x0 <- rep(object$x.scl, nrow(params))
  } 
  
  # Now that we know x0 (either a scaler or a vector), compute f(x0)
  
  likeAtX0 <- function(i, params, x0, like, fit ){
    fx0 <- like(
        a = params[i,]
      , dist = x0[i] - fit$w.lo
      , series = fit$series
      , covars = NULL
      , expansions = fit$expansions
      , w.lo = zero
      , w.hi = fit$w.hi - fit$w.lo
      , pointSurvey = FALSE 
      , scale = TRUE
    ) 
    fx0
  }
  
  f.at.x0 <- sapply(1:nrow(params)
                    , FUN = likeAtX0
                    , params = params
                    , x0 = x0
                    , like = like
                    , fit = object
              )

  scaler <- object$g.x.scl / f.at.x0 # a length n vector, n = nrow(params) 
  
  # Did you know that 'scaler' is ESW?  At least for lines. Makes sense. 1/f(0) = ESW in 
  # the old formulas.
  
  y <- y * scaler  # length(scalar) == nrow(y), so this works right
  
  y <- t(y) # for some reason, we go back to columns. Each column is a dfunc, only now scaled.

  attr(y, "x0") <- x0
  attr(y, "scaler") <- scaler
  
  return( y )  
}
