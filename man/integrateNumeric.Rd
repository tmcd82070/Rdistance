% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/integrateNumeric.R
\name{integrateNumeric}
\alias{integrateNumeric}
\title{Numeric Integration}
\usage{
integrateNumeric(
  object,
  newdata = NULL,
  w.lo = NULL,
  w.hi = NULL,
  Units = NULL,
  expansions = NULL,
  series = NULL,
  isPoints = NULL,
  likelihood = NULL
)
}
\arguments{
\item{object}{An Rdistance model frame or fitted distance function,
normally produced by a call to \code{\link{dfuncEstim}}.}

\item{newdata}{A data frame containing new values for 
covariates at which either
ESW's or EDR's will be computed. If NULL and 
  \code{object} contains covariates, the  
  covariates stored in
  \code{object} are used (like \code{\link{predict.lm}}).
  If not NULL, covariate values in \code{newdata}
  are used. 
  See \bold{Value} section for more information.}
}
\value{
A vector of areas under distance functions. 
If \code{newdata} is specified, return length is 
\code{nrow(newdata)}.  If \code{newdata} is NULL, 
return length is \code{length(distances(object))}.
}
\description{
Numerically integrate under a distance function.
}
\section{Numeric Integration}{
 
Rdistance uses Simpson's composite 1/3 rule to numerically 
integrate distance functions from 0 to 
\code{object$w.hi - object$w.lo}. The number of points evaluated 
during numerical integration is controlled by 
\code{options(Rdistance_intEvalPts)} (default 101).
Option 'Rdistance_intEvalPts' must be odd because Simpson's rule
requires an even number of intervals. 
Lower values of 'Rdistance_intEvalPts' increase calculation speeds; 
but, decrease accuracy.
'Rdistance_intEvalPts' must be >= 5.  A warning is thrown if 
'Rdistance_intEvalPts' < 29. Empirical tests by the author 
suggest 'Rdistance_intEvalPts' values >= 30 are accurate 
to several decimal points for smooth distance functions
(e.g., hazrate, halfnorm, negexp)
and that all 'Rdistance_intEvalPts' >= 101 produce 
identical results if the distance function is smooth. 
  
\emph{Details}: Let \code{n} = \code{options(Rdistance_intEvalPts)}.
Evaluate the distance function at \code{n} equal-spaced 
locations \{f(x0), f(x1), ..., f(xn)\} between 0 and (w.hi - w.lo). 
Simpson's composite approximation to the area under the curve is
\deqn{\frac{1}{3}h(f(x_0) + 4f(x_1) + 2f(x_2) + 
     4f(x_3) + 2f(x_4) + ... + 2f(x_{n-2}) + 
     4f(x_{n-1}) + f(x_{n}))}{(1/3)h(f(x0) + 4f(x1) + 2f(x2) + 
     4f(x3) + 2f(x4) + ... + 2f(x(n-2)) + 4f(x(n-1)) + f(xn))}
where \eqn{h} is the interval size (w.hi - w.lo) / n.

Physical units on the return values
are the original (linear) units if \code{object} contains line-transect data
(e.g., [m]), or square of the original units if \code{object} contains
point-transect data (e.g., [m^2]). Point-transect units are squared because
the likelihood consists of the detection function (which is unitless) 
multiplied by distances (which have units).
}

\examples{

# Fake distance function object w/ minimum inputs for integration
d <- units::set_units(rep(1,4),"m") # Only units needed, not values
df <- data.frame(1) # Need attributes only
attr(df, "transType") <- "line"
obs <- factor(rep(c("obs1", "obs2"), 2))
beta <- c(3.5, -0.5)
w.hi <- 125
w.lo <- 20
ml <- list(
    mf = model.frame(d ~ obs)
  , data = df
  , par = beta 
  , likelihood = "halfnorm"
  , w.lo = units::set_units(w.lo, "m")
  , w.hi = units::set_units(w.hi, "m")
  , outputUnits = units(d)
  , expansions = 0
  , x.scl = units::set_units(w.lo, "m")
  , g.x.scl = 1
)
class(ml) <- "dfunc"
exact <- integrateHalfnorm(ml) # exact area
apprx <- integrateNumeric(ml)  # Numeric approx
pd <- options(digits = 20)
cbind(exact, apprx)
absDiff <- abs(apprx - exact) 
options(pd)

# Approximation to halfnorm is good to this number of digits
equalDigits <- round(log10(absDiff),1)  

}
