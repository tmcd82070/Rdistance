% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/integrationConstant.R
\name{integrationConstant}
\alias{integrationConstant}
\title{integrationConstant - Area under detection functions}
\usage{
integrationConstant(a, ml)
}
\arguments{
\item{a}{A vector of likelihood parameter values. Length and 
meaning depend on \code{ml$series} and \code{ml$expansions}. If no expansion 
terms were called for (i.e., \code{ml$expansions = 0}), the distance 
likelihoods contain one or two canonical parameters (see Details). 
If one or more expansions are called for, coefficients for the 
expansion terms follow coefficients for the canonical parameters.  
i.e., length of this vector must be 
  \code{(num Covars incl. intercept) + expansions + 1*(like \%in\% c("hazrate", "logistic", "huber"))}.}

\item{ml}{Either a Rdistance 'model frame' or an Rdistance 
'fitted object'.  Both are of class "dfunc". 
Rdistance 'model frames' are lists containing components 
necessary to estimate a distance function, but no estimates. 
They contain the data, formula, likelihood name, w.lo, w.hi, 
expansions, transect type, output units, etc.  
Rdistance 'model frames' are typically
produced by calls to \code{\link{parseModel}}. 

Rdistance 'fitted objects'
are typically produced by calls to \code{\link{dfuncEstim}}.
'Fitted objects' are 'model frames'
with additional components such as the parameters estimates, 
log likelihood value, convergence information, and the variance-
covariance matrix of the parameters.}
}
\value{
A vector of scalars the same length as the 
number of distance observations where each value
is the area under \code{ml$likelihood} between 
\code{w.lo} and \code{w.hi}.
This scalar can be used (as a divisor) to scale 
likelihood values such that
the functions integrate to 1.0. i.e., if x = density(\ldots), then
x / \code{integration.constant(density, \ldots)} will integrate to 1.0.
}
\description{
Compute
the area under a distance function between two limits (\code{w.lo}
and \code{w.hi}) using numerical integration
}
\details{
This routine uses Simpson's composite 1/3 rule 
to numerically integrate
\code{ml$likelihood} from \code{ml$w.lo} to \code{ml$w.hi}
(https://en.wikipedia.org/wiki/Simpson's_rule). 
The distance function is evaluated at 201 equal-spaced locations between 
the limits, {f(x0), f(x1), ..., f(200), f(201)}.  Simpson's composite
approximation to the area under the curve is
\deqn{\frac{1}{3}h(f(x_0) + 4f(x_1) + 2f(x_2) + 
     4f(x_3) + 2f(x_4) + ... + 2f(x_{199}) + 
     4f(x_{200}) + f(x_{201}))}{(1/3)h(f(x0) + 4f(x1) + 2f(x2) + 
     4f(x3) + 2f(x4) + ... + 2f(x199) + 4f(x200) + f(x201))}
where \eqn{h} is the interval size (w.hi - w.lo) / 201.
}
\section{Numeric Integration}{
 
Rdistance uses Simpson's composite 1/3 rule to numerically 
integrate under distance functions. The number of points evaluated 
during numerical integration is controlled by 
\code{options(Rdistance_intEvalPts)} (default 101).
Option 'Rdistance_intEvalPts' must be odd because Simpson's rule
requires an even number of intervals (hence, odd number of points). 
Lower values of 'Rdistance_intEvalPts' increase calculation speeds; 
but, decrease accuracy.
'Rdistance_intEvalPts' must be >= 5.  A warning is thrown if 
'Rdistance_intEvalPts' < 29. Empirical tests by the author 
suggest 'Rdistance_intEvalPts' values >= 30 are accurate 
to several decimal points and that all 'Rdistance_intEvalPts' >= 101 produce 
identical results in all but pathological cases.
}

\examples{
# Close to what happens in Rdistance
d <- units::set_units(rep(1,4),"m") # Only units needed, not values
obs <- factor(rep(c("obs1", "obs2"), 2))
ml <- list(
    mf = model.frame(d ~ obs) 
  , likelihood = "halfnorm"
  , expansions = 0
  , w.lo = units::set_units(0, "m")
  , w.hi = units::set_units(125, "m")
  , outputUnits = units(units::set_units(1,"m"))
  , transType = "line"
)
class(ml) <- "dfunc"
integrationConstant(c(log(40), log(.5)), ml)

# Check:
w.hi <- 125
w.lo <- 0
s1 <- 40
s2 <- exp(log(s1) + log(0.5))
obs1Scaler <- (pnorm(w.hi, mean=w.lo, sd = s1) - 0.5) * sqrt(2*pi)*s1
obs2Scaler <- (pnorm(w.hi, mean=w.lo, sd = s2) - 0.5) * sqrt(2*pi)*s2
c(obs1Scaler, obs2Scaler)


}
\seealso{
\code{\link{dfuncEstim}}, \code{\link{halfnorm.like}}
}
\keyword{models}
